{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d486943c-2575-429b-89bd-ffa860519441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAPTURE IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fff607-348c-4212-a553-bd71007e41f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'C' to capture 5 images for Abdullah Nawaz or 'Q' to quit...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def capture_image(student_name, num_images=50):\n",
    "    # Create folder for the student if it doesn't exist\n",
    "    if not os.path.exists(f\"dataset/{student_name}\"):\n",
    "        os.makedirs(f\"dataset/{student_name}\")\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Capture\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    print(\n",
    "        f\"Press 'C' to capture {num_images} images for {student_name} or 'Q' to quit...\"\n",
    "    )\n",
    "\n",
    "    count = 0\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()  # Read frame from the webcam\n",
    "        if ret:\n",
    "            cv2.imshow(\"Capture\", frame)  # Show live feed\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF  # Capture key press\n",
    "\n",
    "            if key == ord(\"c\"):  # Press 'C' to capture image\n",
    "                image_path = f\"dataset/{student_name}/image{count+1}.jpg\"\n",
    "                cv2.imwrite(image_path, frame)  # Save the image\n",
    "                print(f\"Captured image {count+1} for {student_name}: {image_path}\")\n",
    "                count += 1\n",
    "\n",
    "            elif key == ord(\"q\"):  # Press 'Q' to quit capturing\n",
    "                print(\"Quitting image capture.\")\n",
    "                break\n",
    "\n",
    "    # Release webcam and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# Add new student names in the array\n",
    "studentNames = [\"Abdullah Nawaz\"]\n",
    "for studentName in studentNames:\n",
    "    capture_image(studentName, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b27318a-e3f6-463b-a999-af34496c8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2c8f41-ba11-4113-bbd2-e0cd7c59fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_image(image_path, image_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "# Create image pairs function\n",
    "def create_image_pairs(image_dir):\n",
    "    students = os.listdir(image_dir)\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Generate positive pairs (same student)\n",
    "    for student in students:\n",
    "        student_path = os.path.join(image_dir, student)\n",
    "        if not os.path.isdir(student_path):\n",
    "            continue\n",
    "        student_images = os.listdir(student_path)\n",
    "        for i in range(len(student_images)):\n",
    "            for j in range(i + 1, len(student_images)):\n",
    "                img1 = f\"{image_dir}/{student}/{student_images[i]}\"\n",
    "                img2 = f\"{image_dir}/{student}/{student_images[j]}\"\n",
    "                pairs.append([preprocess_image(img1), preprocess_image(img2)])\n",
    "                labels.append(1)\n",
    "\n",
    "    # Generate negative pairs (different students)\n",
    "    for i in range(len(students)):\n",
    "        for j in range(i + 1, len(students)): \n",
    "            student1_path = os.path.join(image_dir, students[i])\n",
    "            student2_path = os.path.join(image_dir, students[j])\n",
    "\n",
    "            if not os.path.isdir(student1_path) or not os.path.isdir(student2_path):\n",
    "                continue\n",
    "            student1_images = os.listdir(student1_path)\n",
    "            student2_images = os.listdir(student2_path)\n",
    "            img1 = f\"{image_dir}/{students[i]}/{random.choice(student1_images)}\"\n",
    "            img2 = f\"{image_dir}/{students[j]}/{random.choice(student2_images)}\"\n",
    "            pairs.append([preprocess_image(img1), preprocess_image(img2)])\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "image_dir = \"dataset\"\n",
    "pairs, labels = create_image_pairs(image_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefc8315-cbe9-4c37-9aa7-9a0f32dfc7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4498c707-c3a1-45bb-857f-ffd6349dc6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "pairs = tf.convert_to_tensor(pairs, dtype=tf.float32)\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Define base network\n",
    "def create_base_network(input_shape=(128, 128, 1)):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (5, 5), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "\n",
    "# Create Siamese network\n",
    "def create_siamese_network(input_shape=(128, 128, 1)):\n",
    "    base_network = create_base_network(input_shape)\n",
    "    input_a = layers.Input(shape=input_shape)\n",
    "    input_b = layers.Input(shape=input_shape)\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    # distance = layers.Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))(\n",
    "    #     [processed_a, processed_b]\n",
    "    # )\n",
    "\n",
    "    l1_distance = layers.Subtract()([processed_a, processed_b])\n",
    "    l1_distance = layers.Activation('relu')(l1_distance)\n",
    "    # l1_distance = layers.Lambda(lambda x: tf.math.abs(x), output_shape=lambda x: x)(l1_distance) \n",
    "    \n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(l1_distance)\n",
    "    return Model([input_a, input_b], output)\n",
    "\n",
    "\n",
    "# Instantiate and compile the model\n",
    "siamese_model = create_siamese_network()\n",
    "siamese_model.compile(\n",
    "    optimizer=Adam(0.0001), loss=BinaryCrossentropy(), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = siamese_model.fit(\n",
    "    [pairs[:, 0], pairs[:, 1]], labels, batch_size=16, epochs=20, validation_split=0.2\n",
    ")\n",
    "\n",
    "# create model dir if not created\n",
    "os.makedirs(\"C:/Users/USER/Documents/GitHub/Facial-Recognition-Attendance-System/model\", exist_ok=True) \n",
    "\n",
    "# Save the model\n",
    "siamese_model.save(\"model/siamese_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e71de0e-ae50-4ab4-9316-e75c4cd3b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "siamese_model = load_model(\"model/siamese_model.keras\", safe_mode=False)\n",
    "\n",
    "# Static image path\n",
    "static_image_path = \"temp-test-image.jpg\" \n",
    "static_image = preprocess_image(static_image_path)\n",
    "\n",
    "# Function to test the static image against all images in the dataset\n",
    "def test_static_image_against_dataset(static_image, dataset_dir, threshold=0.5):\n",
    "    students = os.listdir(dataset_dir)\n",
    "    results = {}\n",
    "\n",
    "    for student in students:\n",
    "        student_path = os.path.join(dataset_dir, student)\n",
    "        if not os.path.isdir(student_path):\n",
    "            continue\n",
    "\n",
    "        student_images = os.listdir(student_path)\n",
    "        match_count = 0\n",
    "\n",
    "        # Compare the static image to each image in this student's folder\n",
    "        for image_name in student_images:\n",
    "            image_path = os.path.join(student_path, image_name)\n",
    "            test_image = preprocess_image(image_path)\n",
    "            \n",
    "            # Predict similarity\n",
    "            prediction = siamese_model.predict([static_image, test_image])\n",
    "            similarity_score = prediction[0][0]\n",
    "            \n",
    "            # Check if similarity score is above threshold\n",
    "            if similarity_score > threshold:\n",
    "                match_count += 1\n",
    "\n",
    "        # Save results for this student\n",
    "        results[student] = match_count\n",
    "\n",
    "    # Print match results\n",
    "    for student, count in results.items():\n",
    "        print(f\"Matches for {student}: {count}/{len(os.listdir(os.path.join(dataset_dir, student)))} images\")\n",
    "\n",
    "# Run the test\n",
    "test_static_image_against_dataset(static_image, \"dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ba84c-454b-4f07-80dc-b886d0499a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing purposes\n",
    "\n",
    "static_image_path = \"dataset\\Muhammad Khan\\image2.jpg\" \n",
    "static_image = preprocess_image(static_image_path)\n",
    "\n",
    "test_image_path = \"dataset\\Omer Khan\\image2.jpg\"\n",
    "\n",
    "# Predict similarity\n",
    "prediction = siamese_model.predict([static_image, test_image])\n",
    "prediction[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
