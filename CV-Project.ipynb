{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Capture Images</h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'C' to capture 50 images for Sarim Toqeer or 'Q' to quit...\n",
      "Captured image 1 for Sarim Toqeer: dataset/Sarim Toqeer/image1.jpg\n",
      "Captured image 2 for Sarim Toqeer: dataset/Sarim Toqeer/image2.jpg\n",
      "Captured image 3 for Sarim Toqeer: dataset/Sarim Toqeer/image3.jpg\n",
      "Captured image 4 for Sarim Toqeer: dataset/Sarim Toqeer/image4.jpg\n",
      "Captured image 5 for Sarim Toqeer: dataset/Sarim Toqeer/image5.jpg\n",
      "Captured image 6 for Sarim Toqeer: dataset/Sarim Toqeer/image6.jpg\n",
      "Captured image 7 for Sarim Toqeer: dataset/Sarim Toqeer/image7.jpg\n",
      "Captured image 8 for Sarim Toqeer: dataset/Sarim Toqeer/image8.jpg\n",
      "Captured image 9 for Sarim Toqeer: dataset/Sarim Toqeer/image9.jpg\n",
      "Captured image 10 for Sarim Toqeer: dataset/Sarim Toqeer/image10.jpg\n",
      "Captured image 11 for Sarim Toqeer: dataset/Sarim Toqeer/image11.jpg\n",
      "Captured image 12 for Sarim Toqeer: dataset/Sarim Toqeer/image12.jpg\n",
      "Captured image 13 for Sarim Toqeer: dataset/Sarim Toqeer/image13.jpg\n",
      "Captured image 14 for Sarim Toqeer: dataset/Sarim Toqeer/image14.jpg\n",
      "Captured image 15 for Sarim Toqeer: dataset/Sarim Toqeer/image15.jpg\n",
      "Captured image 16 for Sarim Toqeer: dataset/Sarim Toqeer/image16.jpg\n",
      "Captured image 17 for Sarim Toqeer: dataset/Sarim Toqeer/image17.jpg\n",
      "Captured image 18 for Sarim Toqeer: dataset/Sarim Toqeer/image18.jpg\n",
      "Captured image 19 for Sarim Toqeer: dataset/Sarim Toqeer/image19.jpg\n",
      "Captured image 20 for Sarim Toqeer: dataset/Sarim Toqeer/image20.jpg\n",
      "Captured image 21 for Sarim Toqeer: dataset/Sarim Toqeer/image21.jpg\n",
      "Captured image 22 for Sarim Toqeer: dataset/Sarim Toqeer/image22.jpg\n",
      "Captured image 23 for Sarim Toqeer: dataset/Sarim Toqeer/image23.jpg\n",
      "Captured image 24 for Sarim Toqeer: dataset/Sarim Toqeer/image24.jpg\n",
      "Captured image 25 for Sarim Toqeer: dataset/Sarim Toqeer/image25.jpg\n",
      "Captured image 26 for Sarim Toqeer: dataset/Sarim Toqeer/image26.jpg\n",
      "Captured image 27 for Sarim Toqeer: dataset/Sarim Toqeer/image27.jpg\n",
      "Captured image 28 for Sarim Toqeer: dataset/Sarim Toqeer/image28.jpg\n",
      "Captured image 29 for Sarim Toqeer: dataset/Sarim Toqeer/image29.jpg\n",
      "Captured image 30 for Sarim Toqeer: dataset/Sarim Toqeer/image30.jpg\n",
      "Captured image 31 for Sarim Toqeer: dataset/Sarim Toqeer/image31.jpg\n",
      "Captured image 32 for Sarim Toqeer: dataset/Sarim Toqeer/image32.jpg\n",
      "Captured image 33 for Sarim Toqeer: dataset/Sarim Toqeer/image33.jpg\n",
      "Captured image 34 for Sarim Toqeer: dataset/Sarim Toqeer/image34.jpg\n",
      "Captured image 35 for Sarim Toqeer: dataset/Sarim Toqeer/image35.jpg\n",
      "Captured image 36 for Sarim Toqeer: dataset/Sarim Toqeer/image36.jpg\n",
      "Captured image 37 for Sarim Toqeer: dataset/Sarim Toqeer/image37.jpg\n",
      "Captured image 38 for Sarim Toqeer: dataset/Sarim Toqeer/image38.jpg\n",
      "Captured image 39 for Sarim Toqeer: dataset/Sarim Toqeer/image39.jpg\n",
      "Captured image 40 for Sarim Toqeer: dataset/Sarim Toqeer/image40.jpg\n",
      "Captured image 41 for Sarim Toqeer: dataset/Sarim Toqeer/image41.jpg\n",
      "Captured image 42 for Sarim Toqeer: dataset/Sarim Toqeer/image42.jpg\n",
      "Captured image 43 for Sarim Toqeer: dataset/Sarim Toqeer/image43.jpg\n",
      "Captured image 44 for Sarim Toqeer: dataset/Sarim Toqeer/image44.jpg\n",
      "Captured image 45 for Sarim Toqeer: dataset/Sarim Toqeer/image45.jpg\n",
      "Captured image 46 for Sarim Toqeer: dataset/Sarim Toqeer/image46.jpg\n",
      "Captured image 47 for Sarim Toqeer: dataset/Sarim Toqeer/image47.jpg\n",
      "Captured image 48 for Sarim Toqeer: dataset/Sarim Toqeer/image48.jpg\n",
      "Captured image 49 for Sarim Toqeer: dataset/Sarim Toqeer/image49.jpg\n",
      "Captured image 50 for Sarim Toqeer: dataset/Sarim Toqeer/image50.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def capture_image(student_name, num_images=50):\n",
    "    # Create folder for the student if it doesn't exist\n",
    "    if not os.path.exists(f\"dataset/{student_name}\"):\n",
    "        os.makedirs(f\"dataset/{student_name}\")\n",
    "\n",
    "    # Initialize webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cv2.namedWindow(\"Capture\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "    print(\n",
    "        f\"Press 'C' to capture {num_images} images for {student_name} or 'Q' to quit...\"\n",
    "    )\n",
    "\n",
    "    count = 0\n",
    "    while count < num_images:\n",
    "        ret, frame = cap.read()  # Read frame from the webcam\n",
    "        if ret:\n",
    "            cv2.imshow(\"Capture\", frame)  # Show live feed\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF  # Capture key press\n",
    "\n",
    "            if key == ord(\"c\"):  # Press 'C' to capture image\n",
    "                image_path = f\"dataset/{student_name}/image{count+1}.jpg\"\n",
    "                cv2.imwrite(image_path, frame)  # Save the image\n",
    "                print(f\"Captured image {count+1} for {student_name}: {image_path}\")\n",
    "                count += 1\n",
    "\n",
    "            elif key == ord(\"q\"):  # Press 'Q' to quit capturing\n",
    "                print(\"Quitting image capture.\")\n",
    "                break\n",
    "\n",
    "    # Release webcam and destroy windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "# Add new student names in the array\n",
    "studentNames = [\"Sarim Toqeer\"]\n",
    "for studentName in studentNames:\n",
    "    capture_image(studentName, num_images=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dataset Processing</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Preprocess function\n",
    "def preprocess_image(image_path, image_size=(128, 128)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, image_size)\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "# Create image pairs function\n",
    "def create_image_pairs(image_dir):\n",
    "    students = os.listdir(image_dir)\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    # Generate positive pairs (same student)\n",
    "    for student in students:\n",
    "        student_path = os.path.join(image_dir, student)\n",
    "        if not os.path.isdir(student_path):\n",
    "            continue\n",
    "        student_images = os.listdir(student_path)\n",
    "        for i in range(len(student_images)):\n",
    "            for j in range(i + 1, len(student_images)):\n",
    "                img1 = f\"{image_dir}/{student}/{student_images[i]}\"\n",
    "                img2 = f\"{image_dir}/{student}/{student_images[j]}\"\n",
    "                pairs.append([preprocess_image(img1), preprocess_image(img2)])\n",
    "                labels.append(1)\n",
    "\n",
    "    # Generate negative pairs (different students)\n",
    "    for i in range(len(students)):\n",
    "        for j in range(i + 1, len(students)): \n",
    "            student1_path = os.path.join(image_dir, students[i])\n",
    "            student2_path = os.path.join(image_dir, students[j])\n",
    "\n",
    "            if not os.path.isdir(student1_path) or not os.path.isdir(student2_path):\n",
    "                continue\n",
    "            student1_images = os.listdir(student1_path)\n",
    "            student2_images = os.listdir(student2_path)\n",
    "            img1 = f\"{image_dir}/{students[i]}/{random.choice(student1_images)}\"\n",
    "            img2 = f\"{image_dir}/{students[j]}/{random.choice(student2_images)}\"\n",
    "            pairs.append([preprocess_image(img1), preprocess_image(img2)])\n",
    "            labels.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "image_dir = \"dataset\"\n",
    "pairs, labels = create_image_pairs(image_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Model</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "pairs = tf.convert_to_tensor(pairs, dtype=tf.float32)\n",
    "labels = tf.convert_to_tensor(labels, dtype=tf.float32)\n",
    "\n",
    "\n",
    "# Define base network\n",
    "def create_base_network(input_shape=(128, 128, 1)):\n",
    "    input_layer = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(64, (7, 7), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (5, 5), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    return Model(input_layer, x)\n",
    "\n",
    "\n",
    "# Create Siamese network\n",
    "def create_siamese_network(input_shape=(128, 128, 1)):\n",
    "    base_network = create_base_network(input_shape)\n",
    "    input_a = layers.Input(shape=input_shape)\n",
    "    input_b = layers.Input(shape=input_shape)\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    # distance = layers.Lambda(lambda tensors: tf.math.abs(tensors[0] - tensors[1]))(\n",
    "    #     [processed_a, processed_b]\n",
    "    # )\n",
    "\n",
    "    l1_distance = layers.Subtract()([processed_a, processed_b])\n",
    "    l1_distance = layers.Activation('relu')(l1_distance)\n",
    "    # l1_distance = layers.Lambda(lambda x: tf.math.abs(x), output_shape=lambda x: x)(l1_distance) \n",
    "    \n",
    "    output = layers.Dense(1, activation=\"sigmoid\")(l1_distance)\n",
    "    return Model([input_a, input_b], output)\n",
    "\n",
    "\n",
    "# Instantiate and compile the model\n",
    "siamese_model = create_siamese_network()\n",
    "siamese_model.compile(\n",
    "    optimizer=Adam(0.0001), loss=BinaryCrossentropy(), metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = siamese_model.fit(\n",
    "    [pairs[:, 0], pairs[:, 1]], labels, batch_size=16, epochs=20, validation_split=0.2\n",
    ")\n",
    "\n",
    "# create model dir if not created\n",
    "os.makedirs(\"C:/Users/USER/Documents/GitHub/Facial-Recognition-Attendance-System/model\", exist_ok=True) \n",
    "\n",
    "# Save the model\n",
    "siamese_model.save(\"model/siamese_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "siamese_model = load_model(\"model/siamese_model.keras\", safe_mode=False)\n",
    "\n",
    "# Static image path\n",
    "static_image_path = \"temp-test-image.jpg\" \n",
    "static_image = preprocess_image(static_image_path)\n",
    "\n",
    "# Function to test the static image against all images in the dataset\n",
    "def test_static_image_against_dataset(static_image, dataset_dir, threshold=0.5):\n",
    "    students = os.listdir(dataset_dir)\n",
    "    results = {}\n",
    "\n",
    "    for student in students:\n",
    "        student_path = os.path.join(dataset_dir, student)\n",
    "        if not os.path.isdir(student_path):\n",
    "            continue\n",
    "\n",
    "        student_images = os.listdir(student_path)\n",
    "        match_count = 0\n",
    "\n",
    "        # Compare the static image to each image in this student's folder\n",
    "        for image_name in student_images:\n",
    "            image_path = os.path.join(student_path, image_name)\n",
    "            test_image = preprocess_image(image_path)\n",
    "            \n",
    "            # Predict similarity\n",
    "            prediction = siamese_model.predict([static_image, test_image])\n",
    "            similarity_score = prediction[0][0]\n",
    "            \n",
    "            # Check if similarity score is above threshold\n",
    "            if similarity_score > threshold:\n",
    "                match_count += 1\n",
    "\n",
    "        # Save results for this student\n",
    "        results[student] = match_count\n",
    "\n",
    "    # Print match results\n",
    "    for student, count in results.items():\n",
    "        print(f\"Matches for {student}: {count}/{len(os.listdir(os.path.join(dataset_dir, student)))} images\")\n",
    "\n",
    "# Run the test\n",
    "test_static_image_against_dataset(static_image, \"dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing purposes\n",
    "\n",
    "static_image_path = \"dataset\\Muhammad Khan\\image2.jpg\" \n",
    "static_image = preprocess_image(static_image_path)\n",
    "\n",
    "test_image_path = \"dataset\\Omer Khan\\image2.jpg\"\n",
    "\n",
    "# Predict similarity\n",
    "prediction = siamese_model.predict([static_image, test_image])\n",
    "prediction[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Model using website code</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Lambda\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "# 1. Embedding Model Definition (Keep as is, working correctly)\n",
    "def build_embedding_model(input_shape=(128, 128, 1), embedding_dim=48):\n",
    "    inputs = Input(input_shape)\n",
    "    x = layers.Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    pooled_output = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(embedding_dim)(pooled_output)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# 2. Improved Contrastive Loss\n",
    "@tf.keras.utils.register_keras_serializable(name=\"contrastive_loss\")\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    y_true = tf.cast(y_true, y_pred.dtype)\n",
    "    square_pred = tf.square(y_pred)\n",
    "    margin_square = tf.square(tf.maximum(margin - y_pred, 0))\n",
    "    return tf.reduce_mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "# 3. Improved Siamese Network\n",
    "def build_siamese_network(input_shape):\n",
    "    base_network = create_base_network(input_shape)\n",
    "    input_a = Input(shape=input_shape)\n",
    "    input_b = Input(shape=input_shape)\n",
    "\n",
    "    processed_a = base_network(input_a)\n",
    "    processed_b = base_network(input_b)\n",
    "\n",
    "    distance = Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([processed_a, processed_b])\n",
    "    outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "\n",
    "    return Model(inputs=[input_a, input_b], outputs=outputs)\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (10, 10), activation=\"relu\")(inputs)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128, (7, 7), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(128, (4, 4), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(256, (4, 4), activation=\"relu\")(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation=\"sigmoid\")(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "# 4. Improved Image Loading and Preprocessing\n",
    "def preprocess_image(image_path, target_size=(128, 128)):\n",
    "    \"\"\"\n",
    "    Preprocesses an image for the Siamese network.\n",
    "    \"\"\"\n",
    "    if isinstance(image_path, str):\n",
    "        # Load from file\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        # Already a numpy array\n",
    "        image = image_path if len(image_path.shape) == 2 else cv2.cvtColor(image_path, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "    return np.expand_dims(image, axis=0)\n",
    "\n",
    "def load_images_from_folder(folder_path, target_size=(128, 128)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = preprocess_image(img_path, target_size)[0]  # Remove the batch dimension\n",
    "            images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "# 5. Improved Pair Creation\n",
    "def create_pairs(data_dir):\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    student_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
    "\n",
    "    for student in student_folders:\n",
    "        student_path = os.path.join(data_dir, student)\n",
    "        images = load_images_from_folder(student_path)\n",
    "\n",
    "        if len(images) < 2:\n",
    "            continue\n",
    "\n",
    "        # Positive pairs\n",
    "        for i in range(len(images) - 1):\n",
    "            pairs.append([images[i], images[i + 1]])\n",
    "            labels.append(1)\n",
    "\n",
    "        # Negative pairs\n",
    "        other_students = [s for s in student_folders if s != student]\n",
    "        for _ in range(len(images)):\n",
    "            neg_student = random.choice(other_students)\n",
    "            neg_path = os.path.join(data_dir, neg_student)\n",
    "            neg_images = load_images_from_folder(neg_path)\n",
    "            if len(neg_images) > 0:\n",
    "                pairs.append([images[random.randint(0, len(images)-1)],\n",
    "                            neg_images[random.randint(0, len(neg_images)-1)]])\n",
    "                labels.append(0)\n",
    "\n",
    "    return [np.array([p[0] for p in pairs]), np.array([p[1] for p in pairs])], np.array(labels)\n",
    "\n",
    "# 6. Improved Testing Function\n",
    "def test_facial_recognition(model, test_image_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Tests a single image against a dataset of known faces.\n",
    "    Returns the best matching student and confidence scores.\n",
    "    \"\"\"\n",
    "    test_image = preprocess_image(test_image_path)\n",
    "    results = []\n",
    "\n",
    "    for student in os.listdir(dataset_path):\n",
    "        student_path = os.path.join(dataset_path, student)\n",
    "        if not os.path.isdir(student_path):\n",
    "            continue\n",
    "\n",
    "        student_scores = []\n",
    "        student_images = load_images_from_folder(student_path)\n",
    "\n",
    "        for ref_image in student_images:\n",
    "            ref_image = np.expand_dims(ref_image, axis=0)\n",
    "            similarity = model.predict([test_image, ref_image], verbose=0)[0][0]\n",
    "            student_scores.append(similarity)\n",
    "\n",
    "        if student_scores:\n",
    "            avg_score = np.mean(student_scores)\n",
    "            max_score = np.max(student_scores)\n",
    "            results.append({\n",
    "                'student': student,\n",
    "                'average_score': avg_score,\n",
    "                'max_score': max_score,\n",
    "                'matches': sum(1 for score in student_scores if score > 0.5)  # This can be adjusted\n",
    "            })\n",
    "\n",
    "    # Sort by average score\n",
    "    results.sort(key=lambda x: x['average_score'], reverse=True)\n",
    "    return results\n",
    "\n",
    "# Training script\n",
    "def train_siamese_network(data_dir, input_shape=(128, 128, 1), epochs=50, batch_size=32):\n",
    "    # Create and compile model\n",
    "    siamese_model = build_siamese_network(input_shape)\n",
    "    siamese_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss=contrastive_loss,\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Create training pairs\n",
    "    train_pairs, train_labels = create_pairs(data_dir)\n",
    "\n",
    "    # Train the model\n",
    "    history = siamese_model.fit(\n",
    "        [train_pairs[0], train_pairs[1]],\n",
    "        train_labels,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "\n",
    "    return siamese_model, history\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Training\n",
    "    data_dir = \"/content/drive/MyDrive/Colab Notebooks/Facial-Recognition-Attendance-System/dataset\"\n",
    "    model, history = train_siamese_network(data_dir)\n",
    "    model.save(\"/content/drive/MyDrive/Colab Notebooks/Facial-Recognition-Attendance-System/model/siamese_model.keras\")\n",
    "\n",
    "    # Testing\n",
    "    test_image_path = \"/content/drive/MyDrive/Colab Notebooks/Facial-Recognition-Attendance-System/dataset/Muhammad Khan/image10.jpg\"\n",
    "    results = test_facial_recognition(model, test_image_path, data_dir)\n",
    "\n",
    "    # Print results\n",
    "    for result in results:\n",
    "        print(f\"Student: {result['student']}\")\n",
    "        print(f\"Average similarity score: {result['average_score']:.3f}\")\n",
    "        print(f\"Maximum similarity score: {result['max_score']:.3f}\")\n",
    "        print(f\"Number of matches: {result['matches']}\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
